cd("../..")
push!(LOAD_PATH, "./src")
cd /Users/adelinehillier/.julia/dev/OceanConvect

using OceanConvect
using Plots

Construct a ProfileData object, ğ’Ÿ, consisting of the data to train on,
and a GP object, ğ’¢, with which to perform the regression.

data
filename = "general_strat_32_profiles.jld2"
problem  = Sequential("T") # v: "T" for temperature profile; "wT" for temperature flux profile
D        = 16       # collapse profile data down to 16 gridpoints
N        = 4        # collect every 4 timesteps' data for training

Now let's define our kernel. We don't know what the best long(length-scale) parameter value is yet so let's guess 0.0 (Î³=1) and see what happens.
Let's use an exponential kernel.

kernel
k        = 1         # kernel function ID
logÎ³     = 0.0      # log(length-scale parameter)
logÏƒ     = 0.0       # log(signal variance parameter)
distance = derivative_distance  # distance metric to use in the kernel
kernel   = get_kernel(k, logÎ³, logÏƒ, distance)

data
ğ’Ÿ = OceanConvect.ModelData.data(filename, problem; D=D, N=N)

model
ğ’¢ = OceanConvect.GaussianProcess.model(ğ’Ÿ; kernel = kernel)

Animate the mean GP prediction.
anim = animate_profile(ğ’¢, ğ’Ÿ)
gif(anim, "animated_profile.gif")

Not great. Let's try to optimize our Î³ value.
We can use get_min_gamma function to search the range -2:0.1:2 for the log(Î³) value that minimizes the mean error on the true check
min_log_param, min_error = get_min_gamma(k, ğ’Ÿ, distance, -2:0.01:2)

Let's create a kernel with the better log(Î³) value, put the new kernel into a new model, and see how it does.
new_kernel = get_kernel(k, min_log_param, logÏƒ, distance)
ğ’¢ = OceanConvect.GaussianProcess.model(ğ’Ÿ; kernel = new_kernel)
anim = animate_profile(ğ’¢, ğ’Ÿ)
gif(anim, "animated_profile_optimized.gif")

There's a lot of flexibility in how we design our kernel function.
We can modify the hyperparameter values, the distance metric, and the type of kernel function.
